%% Resources

% For training and stuff: http://neuralnetworksanddeeplearning.com/chap3.html


% Could summarize this under a bigger chapter:
% DATA ANALYSIS STRATEGIES 

% Intro: Describe dimensionality reduction.

% Machine Learning
% Statistical data analysis (binned likelihood function)

% %-------------------------------------------------------------------------------
\chapter{Machine Learning in High Energy Physics}
\label{chap:ml}

\Minote{}{Maybe use quot: Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E."[18]}

- data-driven era, ML also more and more adopted in HEP
- replacing traditional analysis strategies that rely on a series of boolean selections based on single observables.
- Different applications of ML in ATLAS and throughout HEP community in general: hit reconstruction \ccite{PERF-2012-05} or track finding, object identification, classification of entire events. ().
- ML can leverage multiple variables simultaneously.

- ML is a vast field and has many applications. Therefore, a general introduction is given first, and then the details relevant to the work presented in this thesis explained after.

- Here, used to construct a classifier that predicts the likeliness of an event being a signal.
- Can be done with supervised learning techniques that use MC simulations as labelled data
- The classifier can be directly used in the final statistical analysis of the distribution

% Description of cut-based analysis
% Traditional data analysis techniques in HEP use a sequence of boolean deci- sions followed by statistical analysis on the selected data. Typically, both the individual decisions and the subsequent statistical analysis are based on the distribution of a single ob- served quantity motivated by physics considerations, which is not easily extended to higher dimensions.
% Within HEP this approach is often referred to as multivariate analysis (MVA); however, outside of physics these techniques would be considered examples of machine learning.


\section{Core Concepts and Terminology in Machine Learning}
The basic task of a machine learning algorithm is to find a function $f: X \rightarrow Y$, that maps some higher-dimensional data $X$ onto some target label $Y$, while optimizing a metric of choosing.
This metric is known as \emph{loss function} (also \emph{cost function}), $L(y, f(x))$.
The function that optimizes the loss function is found in a process referred to as \emph{training}, in which a learning algorithm is applied to a set of sample data, known as \emph{training data}.
The space of functions to choose from is constrained by a \emph{model} that can come in various forms, such as boosted decision trees (BDTs), support vector machines (SVMs), or neural networks (NNs). The latter, in particular deep neural networks (DNNs), are by now the most powerful machine learning models and ubiquitous in HEP and many other technology-related fields. \TDnote{[XX]}{Add reference to footnote?} \footnote{The advent of deep neural networks and machine learning in general was facilitated by the growing amount of both computing resources and data, as well as software advancements, in the beginning of the 21$^{\text{th}}$ century}
Details on DNNs are given below, as they are used in the work presented in this thesis.
% % From [1] see above:
% - Search for function f : X -> Y, that maps the higher-dimensional observed data X on some target label Y of lower dimension, while optimizing a metric of choosing. 
% - The metric is known as loss function and labelled as L(y, f(x)). 

% - In a process known as \emph{training}, a learning algorithm is applied to find the function that optimizes the loss function.

% - The space of functions to choose from is constrained by a model that can come in various forms such as BDTs, support vector machines, or neural networks (see the following chapter).

A major goal in machine learning is \emph{generalization}, that is the ability of a trained model to perform well on previously unseen data.
The opposite is the case, if model parameters are chosen based on signatures unique to the training data. This is known as \emph{overtraining} (or \emph{overfitting}). To prevent a model to be overfitted, various so-called \emph{regularization} techniques can be used during the training.
Regularization methods are typically optimized based on how well a trained model generalizes, which can be tested with data not used in the training.


\section{Introduction to Neural Networks}
Neural networks consist of interconnected layers of artificial neurons\footnote{ NNs are therefore also called artificial neural networks (ANNs), which is more descriptive but usually used synonymously with the simple form ``neural networks''.}. An illustration of a fully-connected neural network, where each layer receives inputs only from the previous layer, is shown in \cref{fig:neural-net}. These types of NNs are known as \emph{feedforward} NNs.
The first layer is called the \emph{input layer} and corresponds to the input vector, $\mathbf{x}$. The last layer is called the \emph{output layer}, $\mathbf{y}$, and the layers in between are known as \emph{hidden layers}. Each neuron performs a transformation of the data from the respective previous layer based on an \emph{activation function}, labelled as $h^{(l)}(\cdot)$ for the $l^\text{th}$ layer.
The activation function of the first layer can be regarded as the identity function $h^{(0)}(\mathbf{x}) \equiv \mathbf{x}$.
The artificial neurons are connected via \emph{links} that have weights associated.
A weight labelled with $w^{(l)}_{jk}$ connects the $k^\text{th}$ neuron in the $l^\text{th}$ layer to the $j^\text{th}$ neuron in $(l+1)^\text{th}$ layer.
In addition, each neuron except the ones in the input layer has a so-called \emph{bias}, labelled as $w^{(l)}_{j0}$ for the $j^\text{th}$ neuron in the $l^\text{th}$ layer.
%A neuron is ``activated'' by the data coming from the respective previous layer. 
The activation of the $j^\text{th}$ neuron in the $l^{\text{th}}$ layer can then be described by a recursive relation,
\begin{equation}
    h^{(l)}_j =  h^{(l)} \left( \sum_{k}   w^{(l)}_{jk} h^{(l-1)}_{k}  + w^{(l)}_{j0} \right),
\end{equation}
where the sum is over all neurons $k$ in the $(l-1)^\text{th}$ layer.
% While the number of neurons in the input and output layer are typically chosen based on the problem at hand, the specifics for the hidden layers are usually optimized empirically.  
This equation can be written in matrix form,
\begin{equation}
    \mathbf{h}^{(l+1)} =  h^{(l)} \left( W^{(l)} \mathbf{h}^{(l)}  + \mathbf{w}^{(l)}_{0} \right),
\end{equation}
by defining the weight matrix $W^{(l)} = \left(w^{(l)}_{jk} \right)$, and the vectors corresponding to the activations and bias terms in the $l^\text{th}$ layer as $\mathbf{h}^{(l)}$ and  $\mathbf{w}^{(l)}_0$, respectively.
% Taking a simple network with $N$ inputs, one hidden layer with $H$ artificial neurons, and a single output neuron, the full neural network function can be written as,
% \begin{equation}
%     y(\mathbf{x}, \mathbf{W}) = \sigma \left( \sum_{h=1}^H w^{(2)}_{kh}h^{(1)}\left(  \sum_{n=1}^{N} w^{(1)}_{hn}x_n + w^{(1)}_{h0}    \right) + w^{(2)}_{0} \right),
% \end{equation}
The full function of a simple network with one hidden layer and a single output neuron can then be written as,
\begin{equation}
    y(\mathbf{x}, \mathbf{W}) = h^{(2)} \left( W^{(2)} h^{(1)} \left(  W^{(1)} \mathbf{x} + \mathbf{w}^{(1)}_{0}    \right) + w^{(2)}_{0} \right),
\end{equation}
which simply corresponds to a nonlinear function, controlled by a set of adjustable parameters of weights and biases, that are together labelled as $\mathbf{W}$. Here, the weight matrix $W^{(2)}$ is a vector and the activation function $h^{(2)}(\cdot)$ is the activation of the output neuron.

% In order to understand this transformation, a single artificial neuron is depicted in \cref{fig:single-neuron}. 
The type of activation function can have different forms; typical choices are a logistic sigmoid,
\begin{equation}
    \label{eq:logistic-sigmoid}
    h(x)= \sigma(x) = {\frac {1}{1+e^{-x}}},
\end{equation}
or a so-called Rectified Linear Unit (ReLU) function, defined as
\begin{equation}
    {h(x)= R(x) = \max(0,x)}.    
\end{equation}
\Minote{}{Maybe remove the specifics and move them to the next chapter.}
The same activation function is usually used across all hidden layers.
The output layer typically has a dedicated activation function, tailored to the problem at hand.

The choice of activation functions as well as the number of layers and neurons is known as the \emph{network architecture} in a feedforward NN. The weights of the NN are the free parameters that are to be optimized during the training process.

% Quote from: http://neuralnetworksanddeeplearning.com/chap1.html
%- Up to now, we've been discussing neural networks where the output from one layer is used as input to the next layer. Such networks are called feedforward neural networks.



\begin{figure}[t]
    \newImageResizeCustom{0.9}{figures/data-analysis/neural-network-architecture.png}
    \caption{Example illustration of a fully-connected neural network. The three dots indicate that neural networks can be defined with an arbitrary number of neurons and hidden layers.}
    \label{fig:neural-net}
\end{figure}


% \begin{figure}[t]
%     \newImageResizeCustom{0.7}{figures/data-analysis/single-neuron-illustration.png}
%     \caption{Illustration of a single artificial neuron, including the inputs, $\mathbf{x}$ and $\mathbf{w}$, the bias, $b$, and the activation function $a(\cdot)$ as well as output weight.}
%     \label{fig:single-neuron}
% \end{figure}


\section{Neural Network Training and Hyperparameters}
% Read also here: http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent

The work presented in this thesis uses supervised learning techniques to train a binary classifier that distinguishes between signal-like and background-like events. 
Therefore, only a single output is required, that uses a logistic sigmoid as activation function such that $y = \sigma(x)$, where $\sigma(x)$ is defined as in \cref{eq:logistic-sigmoid}.
The network is trained with MC simulated $pp$ collision events that have ground-truth labels called \emph{target values} in the following. The target value, $t_n$, for a given event $n$ has a value of $t_n = 1$, if the event is a simulated signal event, and $t_n = 0$ otherwise.
The training process is an iterative numerical procedure, during which the free parameters of the network, $\mathbf{W}$, are updated so that the loss function, $L(\mathbf{W})$, is minimized.
The loss function quantifies the difference between the target values and the values predicted by the current NN model. A typical choice is the sum-of-squares loss,
\begin{equation}
   L(\mathbf{W}) = \sum _{n=1}^{N}\left( y(\mathbf{x}_n, \mathbf{W})-t_n \right)^{2}.
\end{equation}
Another commonly used loss function is the so-called \emph{cross-entropy loss},
\begin{equation}
    L(\mathbf{W}) = \sum _{n=1}^{N}\left( t_n \ln y_n + ( 1 - t_n) \ln (1 - y_n) \right).
\end{equation}
To determine how to update the weights, gradient-based optimization algorithms are commonly used, where the new weight is determined by the gradient of the loss function with respect to the weights, 
\begin{equation}
    w^{(\tau+1)} = w^\tau - \eta \grad_{w^{(\tau)}} L(\mathbf{W}),
\end{equation}
where $\eta$ is known as the \emph{learning rate}. 
The initial weights, $w^{(0)}$, are chosen randomly.

The loss is typically evaluated for a subset of the dataset which is referred to as \emph{batch}. After each batch of data, which is denoted as one \emph{iteration}, the weights are adjusted.

The most widely used optimization algorithm is the \emph{gradient descent} or \emph{stochastic gradient descent} algorithm. 

The gradients are computed with a method known as \emph{back propagation}~\ccite{Rumelhart_1986}.

\section{Hyperparameter optimization} 
- A main part of machine learning is to find the most optimal parameters, to optimize the performance.

- Choosing an optimal learning rate can be challenging
- Learning rate schedules help

% @see: https://ruder.io/optimizing-gradient-descent/
% avoiding getting trapped in their numerous suboptimal local minima
% A learning rate that is too small leads to painfully slow convergence, while a learning rate that is too large can hinder convergence and cause the loss function to fluctuate around the minimum or even to diverge.

There are a plethora of gradient descent optimization algorithms that help to overcome these challenges \ccite{ruder2017overview}. The \emph{AdaGrad}~\ccite{adagrad-duchi} algorithm is one such example. It adapts the learning rate based on the size of the gradients at each parameter, which, in layman's words, leads to rare features in the training data being given more weight than frequently occurring features.

- Regularisation techniques: dropout
- Early stopping

- k-fold cross validation to prevent any bias but still exploit significant portion of available data set for training \cref{fig:k-fold-method}.
- CV per definition removes any potential bias that may occur when data is evaluated with a model that was trained with same data.

Train set: train data
Validation set: used during training to ``monitor'' the progress (e.g. for learning rate schedule) of each fold and choose set of hyperparameters (type of input, network architecture, learning rate, regularization technique, optimizers)
Test set: Used for final evaluation of training and test generalizability

- The set of parameters that define the network architecture together with the parameters used in the training are together referred to as hyperparameters.


- grid search

%\section{Multiclass Classification}

\begin{figure}[t]
    \newImageResizeCustom{0.7}{figures/data-analysis/k-fold-illustration.png}
    \caption{Schematic showing the split of the training data into a training (train), validation (val), and test set in a 5-fold cross-validation with interleaved validation and test set.}
    \label{fig:k-fold-method}
\end{figure}
