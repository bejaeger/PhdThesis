\todo{Introduce impact parameter cause it's mentioned in inner detector section}

The theoretical framework described in \cref{sec:sm} allows making predictions about the probabilities of possible outcomes of proton-proton collision events. 
The necessary computations are complex and affected by many aspects, and are continuously being improved by the theoretical particle physics community.
This section provides an overview of the physical observables that are defined at hadron colliders, and gives details on the characteristics that need to be considered when simulating the collision events. 

% What is that sentence???
% As we will see we can separate the process of calculating cross sections between quarks and other soft QCD things.

\subsection{Collision rates}
The whole physics program at collider experiments can more or less be broken down into the measurement of event rates. Comparing the event rates measured in data with the predictions from simulations allow for meaningful statistical inferences.
For a given process $p$, the event rate can be written as
\begin{equation}
  \frac{\mathrm{d}N}{\mathrm{d}t} = \sigma_p \mathcal{L},
\end{equation}
where $\sigma_p$ is the cross-section for process $p$, and $\mathcal{L}$ the luminosity.

The cross-section,
\begin{equation}
  \sigma = \frac{|M|^2}{F} \int \text{d}Q,
\end{equation}
is determined from the so-called matrix element, $M$, and also involves the Lorentz invariant phase space factor d$Q$ and the incident flux in the laboratory, $F$ \cite{Halzen:1984mc}.
The matrix element contains all the dynamical information of the process under investigation and represents the probability of going from an initial state $i$ to a final state $f$. 
A system of rules was invented by Richard Feynman (known as \emph{Feynman rules}) to compute the matrix elements from the Lagrangians. It makes use of graphical representations of the mathematical expressions, known as \emph{Feynman graphs}. More information on the procedure to compute matrix elements can be found in \todo{REF}.

The luminosity, $\mathcal{L}$, is a crucial performance indicator at particle colliders because it only depends on parameters of the accelerator.
%is the proportionality constant that multiplies the cross-section to determine the \emph{event rate} and 
It is given by
\begin{equation}
  \mathcal{L} = f_rn_b\frac{N_p^2}{A},
\end{equation}
where $N_A$ and $N_B$ are the numbers of particles in the colliding bunches labelled as $A$ and $B$; $f_r$ is the rotational frequency of the two bunches; $n_b$ the total number of bunches inside the accelerator; and $A$ the area of interaction. Assuming Gaussian shaped beam profiles the area of interaction can be written as $A = 4\pi \sigma_x \sigma_y$, where $\sigma_{x/y}$ are the horizontal and vertical beam widths.
The integrated luminosity, 
\begin{equation}
  L_\text{int} = \int \mathcal{L} dt,
\end{equation}
is typically quoted to quantify the size of a dataset collected at a collider experiment.

\subsection{Overview of proton-proton collision event}
The phenomenology of proton-proton collisions ($pp$ collisions) is complex because protons are not elementary particles. Protons are compound states of so-called \emph{partons} made up of quarks and gluons.
The scattering of two protons can be described by a hard parton-parton interaction, known as \emph{hard scatter}, and further low energy processes, resulting from the remaining proton remnants not involved in the hard scattering and forming the so-called \emph{underlying event}.
A schematic overview of a hard $pp$ scattering process is illustrated in \cref{fig:ppcol}.
The incoming partons carry a momentum fraction of the proton, which is described with \emph{parton distribution functions} (PDFs).
The initial and final-state particles of the hard scatter can radiate in the form of \emph{inital} (ISR) or \emph{final-state radiation} (FSR). The final-state partons undergo a process called \emph{hadronization} - also called \emph{fragmentation} - due to the confining nature of QCD. They form a spray of colour-neutral hadrons, which are known as particle \emph{jets}.

\begin{figure}
  \newImageResizeCustom{0.8}{figures/schematic_ppcollision.png}
  \caption[Schematic view of a proton-proton collision.]{Schematic view of a proton-proton collision, taken from Ref.~\cite{Bhatti:2010bf}. Details can be found in the text.}
  \label{fig:ppcol}
\end{figure}

\subsection{Partonic cross-sections and parton distribution functions}
The incoming partons interact according to the laws of QCD.
\todo{Difference between strong coupling constant alphas and g', as described in theory chapter!}
An important property of QCD is the energy dependence of the strong coupling constant, $\alpha_s$, as shown in \cref{fig:alphas}.\footnote{The $\alpha_s$ constant is also sometimes referred to as ``running'' coupling constant as it is, in fact, not a constant.} 
Especially the behaviour at low energies, where $\alpha_s$ diverges, has important consequences for physics calculations. It requires to separate the treatment of physics at low energies and high energies: At low energies, the physics can only be described by non-perturbative models. This regime is known as \emph{soft QCD} and comprises \emph{soft interactions} between partons.
At higher energies, perturbative calculations of the matrix elements can be applied. \footnote{The fact that $\alpha_s$ becomes smaller at high energies is also known as \emph{asymptotic freedom} and implies that strongly interacting particles behave like free particles at high energies. Conversely, at small energies, the particles have a strong coupling. This characteristic of QCD leads to \emph{confinement} of quarks inside hadrons.}

With these considerations, the cross section of a hard scattering process between two protons, $p_1$ and $p_2$, can be written as
\begin{equation}
  \sigma(p_1p_2 \to Y) = \sum_{i,j} \int_0^1 \mathrm{d}x_1 \int_0^1 \mathrm{d}x_2 f_i(x_1,\mu_F^2) f_j(x_2,\mu_F^2) \hat{\sigma}_{ij \rightarrow Y}(x_1p_1,x_2p_2,\mu_F,\mu_R), 
  \label{eq:hhxsec}
\end{equation}
where $f_i(x,\mu_F^2)$ are the PDFs, and $\hat{\sigma}_{ij \rightarrow Y}$ is the partonic cross-section of going from initial partons $i$ and $j$ to the final state $Y$.
The parameter $\mu_F$, known as the \emph{factorization scale}, marks the boundary between the low energy processes and the perturbative regime. 
All processes with an energy below the value of $\mu_F$ are considered part of the proton structure and are accounted for within the PDFs. Hence, these non-perturbative soft processes are separated from the hard partonic scattering cross-section, a method that is also known as the \emph{factorization theorem}.
The sum in \cref{eq:hhxsec} runs over all initial state partons $i$ and $j$ inside the hadron, and the integral goes over the momentum fractions $x_1$ and $x_2$ of the full proton momentum.

The PDFs are non-perturbative and quantify the probability of observing a parton $i$ in the proton with a momentum fraction $x_1$ of the total momentum of the proton.
They cannot currently be predicted to the required precision from theoretical principles and must therefore be extracted from experimental data collected at dedicated scattering experiments.
Example PDFs are shown in \cref{fig:pdfs}.
The so-called \emph{DGLAP (Dokshitzer-Gribov-Lipatov-Altarelli-Parisi) evolution equations} \cite{Dokshitzer:1977sg,GRIBOV197178,Altarelli:1977zs} allow transferring the PDFs between different energy scales, which makes them universally applicable to any process. The PDFs are evaluated at the factorization scale, $\mu_F$. 
% Different physics groups provide computations of PDF sets; one of the most recent, the MMHT2014 PDF set, can be seen in \cref{fig:pdfs}. \todo{Update pdf set and plot}
%\Cref{fig:pdfs} shows the most recent PDFs from the MMHT2014 PDF set.
%There are different gorups, which provide PDF computations.
%\footnote{There are different groups, which provide PDF calculations. They are discussed in the most recent LHC Run 2 PDF recommendations \cite{Butterworth:2015oua}.}.
%which include a combination of the CT14 \cite{Dulat:2015mca}, MMHT2014 \cite{Harland-Lang:2014zoa} and NNPDF3.0 \cite{Ball:2014uwa} PDF sets.
%($\mathcal{O}(\alpha_s)$) Order of in mathematic form

\begin{figure}
  \newImageResizeCustom{0.8}{figures/anatomy/nnpdf.png}
  \caption[The NNPDF3.1 NNLO parton distribution functions at two different energy scales, $\mu^2$, and associated 68\% confidence-level uncertainty bands.]{The NNPDF3.1 NNLO parton distribution functions at two different energy scales, $\mu^2$, and associated 68\% confidence-level uncertainty bands. Taken from Ref.~\cite{2017NNPDF}.}
  \label{fig:pdfs}
\end{figure}

%The partonic cross-sections can be computed using Feynman rules.
%The determination of the matrix element (ME) is done with so called \emph{Feynman rules}, which 
The partonic cross-sections depend on the factorization scale, $\mu_F$, and the renormalization scale, $\mu_R$. 
The partonic cross-sections can be calculated as a perturbation series in the running coupling $\alpha_s$:
\begin{equation}
  \hat{\sigma}_{ij \rightarrow Y} = \alpha^k_S \sum_{n=0}^{m} c^{(n)}\alpha_s^n,
  \label{eq:alphaexp}
\end{equation}
where the coefficients $c^{(n)}$ are functions of the kinematic variables $x_1$ and $x_2$ and $\mu_F$. The term corresponding to $m=0$ is usually referred to as \emph{leading order} (LO), the next higher order, $m=1$, as \emph{next-to-leading order} (NLO), and so on.
The leading power $k$ in \cref{eq:alphaexp} is specified by the process under consideration. Most processes relevant for this thesis start contributing at $k=0$, while some sub-processes have $k=2$.\footnote{All cross sections of interest in this thesis are available at NLO, some of them at NNLO or even higher order. See chapter \cref{sec:dataandmc} for details.}
%For the Higgs gluon-fusion cross-section there exist NNNLO calculations \cite{Anastasiou:2015ema}.}
When computing particle-production cross-sections, all the different interaction modes that lead to the same particle being produced need to be taken into account. This also involves the inclusion of different orders in $\alpha_s$.
The individual contributing processes can be displayed graphically with so called \emph{Feynman diagrams}. The corresponding set of rules, the \emph{Feynman rules}, provide the mathematical baseline for the computation of the matrix elements. The Feynman rules can be derived from the Lagrangian of the underlying theory.
This procedure is detailed in various textbooks, for example in Ref.~\cite{Griffiths:111880}.

%In so called \emph{Feynman diagrams} the scattering processes can be illustrated and the cross sections can be computed at fixed order using the \emph{Feynman rules}.
When including higher orders in $\alpha_s$ in the matrix-element calculation, loop corrections and real gluon emissions introduce divergences in the cross section. %\cref{fig:loops} illustrates these contributions with exemplary Feynman diagrams for different orders in $\alpha_s$.
%($\mathcal{O}(\alpha_s)$ and higher)
%singularities in the cross-section.

The arising infinities can be absorbed by redefining the coupling and mass parameters by introducing a dependence on the so called \emph{renormalization scale} $\mu_R$.
\todo{say that this is an essential part of the SM, that it is renormalizable}
\todo{Maybe provide dedicated section for this?!}

%\todo{say more about collinear and soft divergencies? -> Ja wegen infrared safe später beim jet algorithm}
There exist different approaches for choosing the scale $\mu_R$, at which the coupling $\alpha_s$ is evaluated, known as \emph{renormalization schemes}, but there is no prove of any of them being correct.
Various textbooks, for example Ref.~\cite{Peskin:1995ev}, provide detailed discussions on different renormalization schemes.

\Cref{fig:xsec} shows the cross sections for a variety of different processes. There is a huge span of many orders of magnitudes between different cross sections. Higgs boson production at a centre-of-mass energy of 13\,\TeV, for example, is highly suppressed ($10^{-2}\,\text{events}/s$) with respect to the total cross section ($10^8\,\text{events}/s$) when considering a luminosity of $10^{33}\mathrm{cm^{-1}s^{-1}}$.
An important feature is that the cross sections are not dependent on the renormalization scale, as well as the factorization scale, when infinite orders in $\alpha_s$ would be included. There are remaining dependencies at fixed order. Resulting systematic uncertainties are most often quantified by varying the scales over some reasonable range and are incorporated in the analysis.
%However, it is known that the theoretical error on a quantity, which is calculated to $\mathcal{O(\alpha_s^n}$, is always $\mathcal{O(\alpha_s^{n+1})}$. The remaining theoretical error can be quantified
%MMHT2014 NNLO PDFs

\begin{figure}
  \newImageScale{figures/crosssections2012_v5.pdf}{0.45}
  \caption[Cross sections for proton collisions as a function of centre-of-mass energy $\sqrt{s}$.]{Cross sections for proton collisions as a function of centre-of-mass energy $\sqrt{s}$. Proton-antiproton-collision cross-sections are considered for energies $\sqrt{s} < 4\,\TeV$ and proton-proton-collision cross-sections for higher energies. Taken from Ref.~\cite{ref:plotsStirling}.}
  \label{fig:xsec}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NEED SECTION ON:
% Generation of MC events
% Comment from BERND to "Detector simulation" section in experimental chapter::
% I believe this statemtn "Simulations of the ATLAS detector are required in order to generate full Monte Carlo events” needs to be more precise. Why do we have to simulate collisions in the first place? Probably some discussion about quantum mechanics and its probabilistic nature which makes its way all the way to how we analyze data
\subsection{Event Generation}




\subsection{Soft QCD: Minimum bias, pile-up, ...?}
% Mention in Event Generation subsection, see Master thesis!

% Comment from Bernd:
%Before you can talk about "hard-scatter vertex or from pile-up”, you may have to introduce them. E.g. have a section on Hadron collider physics that goes through these terms?

\Rinote{}{Where else should I talk about pile-up!? what is pile-up? HERE! Pile-up reweighting? analysis section. Pile-up as nuisance for jet measurements? -> JER calibration chapter, pile-up in LHC section as something intrinsic to pp collision event?}

->  Ruthmann has a nice section about it!
From Sommer: "Additional in- elastic, minimum-bias like pp collisions (pile-up) are generated using Pythia8 and overlaid."
Scope:
- I should explain concepts like luminosity blocks  / bunch spacing and stuff in Data Taking Section
- Then I can explain different pile-up conditions here.
- This will be valuable to understand the noise term measurement which exactly tries to measure the noise term!
- Also look back at discussion on skype with Brian about pile-up (actual mu vs average mu and so on)

Checkout this section for pile-up overlay

https://indico.cern.ch/event/1003305/contributions/4236702/attachments/2202625/3728039/PileUpTaskForcePandPPlenaryMarch2021.pdf

